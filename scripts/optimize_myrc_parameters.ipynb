{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef_-nPOvPBz5",
        "outputId": "555a843b-fac7-4c68-f23d-ac7ea42e5a0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/eeg_data')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/eeg_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e63VQJvQl4dE",
        "outputId": "6575a521-74ae-4f40-ff33-46011c5a12a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config.py\t\t  ExractFeatures.py\t       __pycache__\ttensorPCA.py\n",
            "config_trial_spikes.yalm  load_files_trials_spikes.py  session_data.py\tutils.py\n",
            "eeg.py\t\t\t  MyRC_ESN.py\t\t       subject.py\n"
          ]
        }
      ],
      "source": [
        "!ls ./base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gLTWIziX5Rv",
        "outputId": "0d07474b-7d84-4b76-b82f-7af7d491cb92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.7.1-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.6.2)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.7.1\n",
            "Collecting yasa\n",
            "  Downloading yasa-0.6.5-py2.py3-none-any.whl (33.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from yasa) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from yasa) (1.11.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from yasa) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from yasa) (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from yasa) (0.13.1)\n",
            "Requirement already satisfied: mne>=1.3 in /usr/local/lib/python3.10/dist-packages (from yasa) (1.7.1)\n",
            "Requirement already satisfied: numba>=0.57.1 in /usr/local/lib/python3.10/dist-packages (from yasa) (0.58.1)\n",
            "Collecting antropy (from yasa)\n",
            "  Downloading antropy-0.1.6.tar.gz (17 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from yasa) (1.2.2)\n",
            "Collecting tensorpac>=0.6.5 (from yasa)\n",
            "  Downloading tensorpac-0.6.5-py3-none-any.whl (423 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.6/423.6 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyriemann>=0.2.7 (from yasa)\n",
            "  Downloading pyriemann-0.6-py2.py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sleepecg>=0.5.0 (from yasa)\n",
            "  Downloading sleepecg-0.5.8-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (424 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.2/424.2 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lspopt (from yasa)\n",
            "  Downloading lspopt-1.3.0-py2.py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from yasa) (7.7.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from yasa) (1.4.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (from yasa) (4.1.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne>=1.3->yasa) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne>=1.3->yasa) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne>=1.3->yasa) (0.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne>=1.3->yasa) (24.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne>=1.3->yasa) (1.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne>=1.3->yasa) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->yasa) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->yasa) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->yasa) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->yasa) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->yasa) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->yasa) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->yasa) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57.1->yasa) (0.41.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->yasa) (3.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.0 in /usr/local/lib/python3.10/dist-packages (from sleepecg>=0.5.0->yasa) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from sleepecg>=0.5.0->yasa) (2.31.0)\n",
            "Collecting stochastic (from antropy->yasa)\n",
            "  Downloading stochastic-0.7.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->yasa) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->yasa) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->yasa) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->yasa) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->yasa) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->yasa) (3.0.11)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->yasa) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->yasa) (2024.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->yasa) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->yasa) (6.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->yasa) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets->yasa)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->yasa) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->yasa) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->yasa) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->yasa) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->yasa) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->yasa) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne>=1.3->yasa) (4.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->yasa) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->sleepecg>=0.5.0->yasa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->sleepecg>=0.5.0->yasa) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->sleepecg>=0.5.0->yasa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->sleepecg>=0.5.0->yasa) (2024.6.2)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->yasa) (6.5.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne>=1.3->yasa) (2.1.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->yasa) (0.8.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->yasa) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->yasa) (0.2.13)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (4.19.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.18.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.2.1)\n",
            "Building wheels for collected packages: antropy\n",
            "  Building wheel for antropy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antropy: filename=antropy-0.1.6-py3-none-any.whl size=16878 sha256=24ca505d1ffa2c3bc796038b6d5cc002056202ba9b5d48537bf762b6cbcbaac6\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/22/06/e91d7bb213c7133d5e2eb34258623e1e19928d5f05e1ee6812\n",
            "Successfully built antropy\n",
            "Installing collected packages: jedi, tensorpac, stochastic, sleepecg, lspopt, pyriemann, antropy, yasa\n",
            "Successfully installed antropy-0.1.6 jedi-0.19.1 lspopt-1.3.0 pyriemann-0.6 sleepecg-0.5.8 stochastic-0.7.0 tensorpac-0.6.5 yasa-0.6.5\n",
            "Collecting dotmap\n",
            "  Downloading dotmap-1.3.30-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: dotmap\n",
            "Successfully installed dotmap-1.3.30\n",
            "Collecting nilearn\n",
            "  Downloading nilearn-0.10.4-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.4.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nilearn) (4.9.4)\n",
            "Requirement already satisfied: nibabel>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (4.0.2)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nilearn) (24.1)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.11.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel>=4.0.0->nilearn) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2024.6.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->nilearn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->nilearn) (1.16.0)\n",
            "Installing collected packages: nilearn\n",
            "Successfully installed nilearn-0.10.4\n",
            "Collecting mne_connectivity\n",
            "  Downloading mne_connectivity-0.7.0-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mne>=1.6 in /usr/local/lib/python3.10/dist-packages (from mne_connectivity) (1.7.1)\n",
            "Collecting netCDF4>=1.6.5 (from mne_connectivity)\n",
            "  Downloading netCDF4-1.7.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from mne_connectivity) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from mne_connectivity) (2.0.3)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mne_connectivity) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne_connectivity) (4.66.4)\n",
            "Collecting xarray>=2023.11.0 (from mne_connectivity)\n",
            "  Downloading xarray-2024.6.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne>=1.6->mne_connectivity) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne>=1.6->mne_connectivity) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne>=1.6->mne_connectivity) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne>=1.6->mne_connectivity) (3.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne>=1.6->mne_connectivity) (24.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne>=1.6->mne_connectivity) (1.8.2)\n",
            "Collecting cftime (from netCDF4>=1.6.5->mne_connectivity)\n",
            "  Downloading cftime-1.6.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from netCDF4>=1.6.5->mne_connectivity) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.2->mne_connectivity) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.2->mne_connectivity) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.2->mne_connectivity) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne>=1.6->mne_connectivity) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne>=1.6->mne_connectivity) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne>=1.6->mne_connectivity) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne>=1.6->mne_connectivity) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne>=1.6->mne_connectivity) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne>=1.6->mne_connectivity) (3.1.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne>=1.6->mne_connectivity) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne>=1.6->mne_connectivity) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.2->mne_connectivity) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne>=1.6->mne_connectivity) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.6->mne_connectivity) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.6->mne_connectivity) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.6->mne_connectivity) (2.0.7)\n",
            "Installing collected packages: cftime, netCDF4, xarray, mne_connectivity\n",
            "  Attempting uninstall: xarray\n",
            "    Found existing installation: xarray 2023.7.0\n",
            "    Uninstalling xarray-2023.7.0:\n",
            "      Successfully uninstalled xarray-2023.7.0\n",
            "Successfully installed cftime-1.6.4 mne_connectivity-0.7.0 netCDF4-1.7.1.post1 xarray-2024.6.0\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mne\n",
        "!pip install yasa\n",
        "!pip install dotmap\n",
        "!pip install nilearn\n",
        "!pip install mne_connectivity\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Listado ficheros datasets creados de los datos raw\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def read_files_and_show (directory = 'dataset'):\n",
        "    # Verifica si el directorio existe\n",
        "    if not os.path.exists (directory):\n",
        "        print(f\"El directorio {directory} no existe.\")\n",
        "        return\n",
        "\n",
        "    # Obtiene la lista de archivos en el subdirectorio\n",
        "    files = [f for f in os.listdir(directory) if f.endswith('.npy')]\n",
        "\n",
        "    # Verifica si hay archivos en el directorio\n",
        "    if not files:\n",
        "        print(f\"No se encontraron archivos .npy en el directorio {directory}.\")\n",
        "        return\n",
        "\n",
        "    # Lee cada archivo y muestra sus dimensiones\n",
        "    for file in files:\n",
        "        path_file = os.path.join (directory, file)\n",
        "        try:\n",
        "            data = np.load (path_file)\n",
        "            print(f\"El archivo {file} tiene dimensiones: {data.shape}\")\n",
        "        except Exception as e:\n",
        "            print(f\"No se pudo leer el archivo {file}: {e}\")\n",
        "\n",
        "# Llamada a la función\n",
        "read_files_and_show ()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISdmqXEWHW8B",
        "outputId": "a0a3b046-2225-41b8-f040-5e25ca80b4ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El archivo dt_Younger_s_ICA_features_30_4.npy tiene dimensiones: (23, 360, 31)\n",
            "El archivo dt_Older_s_ICA_features_30_4.npy tiene dimensiones: (24, 360, 31)\n",
            "El archivo dt_Younger_s_ICA_30_4.npy tiene dimensiones: (23, 39680, 17)\n",
            "El archivo dt_Older_s_ICA_30_4.npy tiene dimensiones: (24, 39680, 17)\n",
            "El archivo dt_Younger_s_features_30_4.npy tiene dimensiones: (23, 360, 31)\n",
            "El archivo dt_Older_s_features_30_4.npy tiene dimensiones: (24, 360, 31)\n",
            "El archivo dt_Younger_s_30_4.npy tiene dimensiones: (23, 39680, 17)\n",
            "El archivo dt_Older_s_30_4.npy tiene dimensiones: (24, 39680, 17)\n",
            "El archivo dt_Younger_z_ICA_features_30_4.npy tiene dimensiones: (23, 296, 31)\n",
            "El archivo dt_Older_z_ICA_features_30_4.npy tiene dimensiones: (24, 296, 31)\n",
            "El archivo dt_Younger_z_ICA_30_4.npy tiene dimensiones: (23, 39680, 9)\n",
            "El archivo dt_Older_z_ICA_30_4.npy tiene dimensiones: (24, 39680, 9)\n",
            "El archivo dt_Younger_z_features_30_4.npy tiene dimensiones: (23, 296, 31)\n",
            "El archivo dt_Older_z_features_30_4.npy tiene dimensiones: (24, 296, 31)\n",
            "El archivo dt_Younger_z_30_4.npy tiene dimensiones: (23, 39680, 9)\n",
            "El archivo dt_Older_z_30_4.npy tiene dimensiones: (24, 39680, 9)\n",
            "El archivo dt_Younger_d_ICA_features_30_4.npy tiene dimensiones: (23, 520, 31)\n",
            "El archivo dt_Older_d_ICA_features_30_4.npy tiene dimensiones: (24, 520, 31)\n",
            "El archivo dt_Younger_d_ICA_30_4.npy tiene dimensiones: (23, 39680, 37)\n",
            "El archivo dt_Older_d_ICA_30_4.npy tiene dimensiones: (24, 39680, 37)\n",
            "El archivo dt_Younger_d_features_30_4.npy tiene dimensiones: (23, 520, 31)\n",
            "El archivo dt_Older_d_features_30_4.npy tiene dimensiones: (24, 520, 31)\n",
            "El archivo dt_Younger_d_30_4.npy tiene dimensiones: (23, 39680, 37)\n",
            "El archivo dt_Older_d_30_4.npy tiene dimensiones: (24, 39680, 37)\n",
            "El archivo dt_Younger_i_ICA_features_30_4.npy tiene dimensiones: (23, 512, 31)\n",
            "El archivo dt_Older_i_ICA_features_30_4.npy tiene dimensiones: (24, 512, 31)\n",
            "El archivo dt_Younger_i_ICA_30_4.npy tiene dimensiones: (23, 39680, 36)\n",
            "El archivo dt_Older_i_ICA_30_4.npy tiene dimensiones: (24, 39680, 36)\n",
            "El archivo dt_Younger_i_features_30_4.npy tiene dimensiones: (23, 512, 31)\n",
            "El archivo dt_Older_i_features_30_4.npy tiene dimensiones: (24, 512, 31)\n",
            "El archivo dt_Younger_i_30_4.npy tiene dimensiones: (23, 39680, 36)\n",
            "El archivo dt_Older_i_30_4.npy tiene dimensiones: (24, 39680, 36)\n",
            "El archivo dt_Younger_eeg_ICA_features_30_4.npy tiene dimensiones: (23, 736, 31)\n",
            "El archivo dt_Older_eeg_ICA_features_30_4.npy tiene dimensiones: (24, 736, 31)\n",
            "El archivo dt_Younger_eeg_ICA_30_4.npy tiene dimensiones: (23, 39680, 64)\n",
            "El archivo dt_Older_eeg_ICA_30_4.npy tiene dimensiones: (24, 39680, 64)\n",
            "El archivo dt_Younger_eeg_features_30_4.npy tiene dimensiones: (23, 736, 31)\n",
            "El archivo dt_Older_eeg_features_30_4.npy tiene dimensiones: (24, 736, 31)\n",
            "El archivo dt_Younger_eeg_30_4.npy tiene dimensiones: (23, 39680, 64)\n",
            "El archivo dt_Older_eeg_30_4.npy tiene dimensiones: (24, 39680, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Búsqueda parametros optimos del modelo MyRC apra cada dataset creado\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import optuna\n",
        "import argparse\n",
        "import warnings\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nilearn import plotting\n",
        "from scipy.stats import norm\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# Import specific functions/classes/modules\n",
        "from base.eeg import (\n",
        "    all_channels, eeg_channels, eog_channels, process_eeg_data_with_ica,\n",
        "    process_eeg_data_without_ica\n",
        ")\n",
        "\n",
        "from base.MyRC_ESN import (\n",
        "    MyRC, MyESN\n",
        ")\n",
        "\n",
        "def standardize_eeg_signals_opt( X ):\n",
        "    \"\"\"\n",
        "    Estandariza las señales de EEG para cada canal de cada sujeto.\n",
        "\n",
        "    Args:\n",
        "        X (np.ndarray): Datos de entrada con forma (n_subjects, n_samples, n_channels).\n",
        "\n",
        "    Returns:\n",
        "        X_standardized (np.ndarray): Datos estandarizados con la misma forma que X.\n",
        "    \"\"\"\n",
        "    X_standardized = np.copy( X )\n",
        "\n",
        "    def standardize_channel( channel_data ):\n",
        "        scaler = StandardScaler()\n",
        "        return scaler.fit_transform( channel_data.reshape( -1, 1 ) ).flatten()\n",
        "\n",
        "    for i in range( X.shape[0] ):\n",
        "        X_standardized[i] = np.apply_along_axis( standardize_channel, 0, X[i] )\n",
        "\n",
        "    return X_standardized\n",
        "\n",
        "def minmax_normalize_eeg_signals_opt( X ):\n",
        "    \"\"\"\n",
        "    Normaliza las señales de EEG para cada canal de cada sujeto usando Min-Max.\n",
        "\n",
        "    Args:\n",
        "        X (np.ndarray): Datos de entrada con forma (n_subjects, n_samples, n_channels).\n",
        "\n",
        "    Returns:\n",
        "        X_normalized (np.ndarray): Datos normalizados con la misma forma que X.\n",
        "    \"\"\"\n",
        "    X_normalized = np.copy( X )\n",
        "\n",
        "    def normalize_channel( channel_data ):\n",
        "        scaler = MinMaxScaler()\n",
        "        return scaler.fit_transform( channel_data.reshape( -1, 1 ) ).flatten()\n",
        "\n",
        "    for i in range( X.shape[0] ):\n",
        "        X_normalized[i] = np.apply_along_axis( normalize_channel, 0, X[i] )\n",
        "\n",
        "    return X_normalized\n",
        "\n",
        "def check_and_load_files( file_path, verbose=False ):\n",
        "    \"\"\"\n",
        "    Verifica si el archivo existe y lo carga. Asigna etiquetas basadas en el nombre del archivo.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Ruta del archivo a cargar.\n",
        "        verbose (bool): Indica si se debe mostrar información detallada.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Dataset cargado y etiquetas.\n",
        "    \"\"\"\n",
        "    # Check if the file exists\n",
        "    if not os.path.exists( file_path ):\n",
        "        raise FileNotFoundError( f\"El fichero {file_path} no se encuentra disponible.\" )\n",
        "\n",
        "    # Load the dataset\n",
        "    dataset = np.load( file_path )\n",
        "\n",
        "    if verbose: print( f'dataset: {dataset.shape}' )\n",
        "\n",
        "    # Assuming labels are included in the filename, adjust as necessary\n",
        "    # For this example, we assume the younger/older distinction and their respective counts\n",
        "    if 'younger' in file_path:\n",
        "        labels = [0] * 23\n",
        "    elif 'older' in file_path:\n",
        "        labels = [1] * 24\n",
        "    else:\n",
        "        raise ValueError( \"Filename must contain 'younger' or 'older' to create labels.\" )\n",
        "\n",
        "    labels = np.array( labels )\n",
        "\n",
        "    return dataset, labels\n",
        "\n",
        "def train_reservoir( config, X, Y, verbose=False ):\n",
        "    \"\"\"\n",
        "    Entrena el modelo de reservorio.\n",
        "\n",
        "    Args:\n",
        "        config (dict): Configuración del modelo.\n",
        "        X (np.ndarray): Datos de entrada.\n",
        "        Y (np.ndarray): Etiquetas.\n",
        "        verbose (bool): Indica si se debe mostrar información detallada.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Estado del reservorio, representación de entrada y etiquetas.\n",
        "    \"\"\"\n",
        "    if verbose: print( f\"config: {config}\" )\n",
        "    model_clus = MyESN( config )\n",
        "\n",
        "    X_ = standardize_eeg_signals_opt( X )\n",
        "\n",
        "    if verbose: print( f'X: {X.shape}' )\n",
        "    if verbose: print( f'X_: {X_.shape}' )\n",
        "\n",
        "    my_rc_clus         = MyRC( model_clus, config )\n",
        "    result_rc          = my_rc_clus.fit( X_ )\n",
        "\n",
        "    rc_state           = result_rc[0]\n",
        "    rc_dim_states      = result_rc[1]\n",
        "    input_repr         = result_rc[2]\n",
        "    output_redout_layer= result_rc[3]\n",
        "\n",
        "    if verbose:\n",
        "        print( f'config: {config}' )\n",
        "        print( f'rc_state: {rc_state.shape}' )\n",
        "        print( f'rc_dim_states: {rc_dim_states.shape}' )\n",
        "        print( f'input_repr: {input_repr.shape}' )\n",
        "        print( f'output_redout_layer: {output_redout_layer.shape}' )\n",
        "\n",
        "    return rc_state, input_repr, Y\n",
        "# Función para ignorar advertencias de tipo FutureWarning\n",
        "def warn (*args, **kwargs):\n",
        "    pass\n",
        "def calculate_kmeans_and_metrics (X, Y, verbose):\n",
        "    similarity_matrix = cosine_similarity (X)\n",
        "    np.fill_diagonal (similarity_matrix, 0)\n",
        "\n",
        "    kmeans = KMeans (n_clusters=2)\n",
        "    kmeans.fit_transform (similarity_matrix)\n",
        "    predicted_labels_similarity = kmeans.labels_\n",
        "\n",
        "    kmeans.fit_transform (X)\n",
        "    predicted_labels_X = kmeans.labels_\n",
        "\n",
        "    return predicted_labels_similarity, predicted_labels_X\n",
        "\n",
        "def log_results(file_log, trial, config, report, accuracy_value, f1_score, auc_roc_value):\n",
        "    with open (file_log, \"a\") as f:\n",
        "        f.write (f\"Trial {trial.number}\\n\")\n",
        "        f.write (f\"Configuration: {config}\\n\")\n",
        "        f.write (f\"Report: {report}\\n\")\n",
        "        f.write (f\"accu: {accuracy_value}\\n\")\n",
        "        f.write (f\"f1_score: {f1_score}\\n\")\n",
        "        f.write (f\"auc_roc_value: {auc_roc_value}\\n\")\n",
        "        f.write (\"\\n\")\n",
        "\n",
        "def evaluate_accuracy(trial, X, Y, state, file_prefix, verbose=False):\n",
        "\n",
        "    predicted_labels_similarity, predicted_labels_X = calculate_kmeans_and_metrics(X, Y, verbose)\n",
        "\n",
        "    labels = Y\n",
        "    if verbose:\n",
        "        print(f'trial: {trial}')\n",
        "        print(f'\\t labels: {labels}')\n",
        "        print(f'\\t predicted_labels_similarity: {predicted_labels_similarity}')\n",
        "        print(f'\\t predicted_labels_X: {predicted_labels_X}')\n",
        "\n",
        "    # Generate and log metrics for similarity matrix\n",
        "    report_similarity         = classification_report (labels, predicted_labels_similarity, output_dict = True)\n",
        "    f1_score_similarity       = report_similarity ['weighted avg']['f1-score']\n",
        "    auc_roc_value_similarity  = roc_auc_score (labels, predicted_labels_similarity)\n",
        "    accuracy_value_similarity = accuracy_score (labels, predicted_labels_similarity)\n",
        "\n",
        "    file_log_similarity = f\"./optim_param/{file_prefix}_similarity.txt\"\n",
        "    log_results (file_log_similarity, trial, trial.params, report_similarity, accuracy_value_similarity, f1_score_similarity, auc_roc_value_similarity)\n",
        "\n",
        "    # Generate and log metrics for X\n",
        "    report_X         = classification_report (labels, predicted_labels_X, output_dict=True)\n",
        "    f1_score_X       = report_X ['weighted avg']['f1-score']\n",
        "    auc_roc_value_X  = roc_auc_score (labels, predicted_labels_X)\n",
        "    accuracy_value_X = accuracy_score (labels, predicted_labels_X)\n",
        "\n",
        "    file_log_X = f\"./optim_param/{file_prefix}_X.txt\"\n",
        "    log_results (file_log_X, trial, trial.params, report_X, accuracy_value_X, f1_score_X, auc_roc_value_X)\n",
        "\n",
        "    if verbose:\n",
        "        print(f'\\t f1_score_similarity::state = {state}: {f1_score_similarity}')\n",
        "        print(f'\\t auc_roc_value_similarity:state = {state}; {auc_roc_value_similarity}')\n",
        "        print(f'\\t accuracy_value_similarity:state = {state}; {accuracy_value_similarity}')\n",
        "\n",
        "        print(f'\\t f1_score_X::state = {state}: {f1_score_X}')\n",
        "        print(f'\\t accuracy_value_X:state = {state}; {accuracy_value_X}')\n",
        "        print(f'\\t auc_roc_value_X:state = {state}; {auc_roc_value_X}')\n",
        "\n",
        "    return accuracy_value_similarity, accuracy_value_X\n",
        "\n",
        "\n",
        "def train_and_evaluate_model ( trial, X, Y, file_prefix, verbose = False ):\n",
        "    \"\"\"\n",
        "    Entrena y evalúa el modelo de EEG.\n",
        "\n",
        "    Args:\n",
        "        trial (optuna.Trial): Prueba actual de Optuna.\n",
        "        X (np.ndarray): Datos de entrada.\n",
        "        Y (np.ndarray): Etiquetas.\n",
        "        file_prefix (str): Prefijo para el archivo de log.\n",
        "        verbose (bool): Indica si se debe mostrar información detallada.\n",
        "\n",
        "    Returns:\n",
        "        float: Precisión de la evaluación del modelo.\n",
        "    \"\"\"\n",
        "\n",
        "    config = {\n",
        "        'seed':0,\n",
        "        'init_type':trial.suggest_categorical('init_type', ['orthogonal', 'trunc_normal', 'binorm']),\n",
        "        'init_std':trial.suggest_float('init_std', 0.01, 0.05, log = True),\n",
        "        'init_mean':0,\n",
        "        'input_size': X.shape[2],\n",
        "        'n_internal_units': X.shape[2]*10,\n",
        "        'spectral_radius': trial.suggest_float('spectral_radius', 0.96, 1.00),\n",
        "        'leak': trial.suggest_float('leak', 0.38, 0.96),\n",
        "        'input_scaling': 0.10,\n",
        "        'nonlinearity': trial.suggest_categorical('nonlinearity', ['relu', 'tanh']),\n",
        "        'connectivity': trial.suggest_float('connectivity', 0.1, 0.5),\n",
        "        'noise_level': trial.suggest_float('noise_level', 0.1, 10.00),\n",
        "        'n_drop': trial.suggest_int('n_drop', 0, 100) if trial.suggest_categorical('n_drop_present', [True, False]) else None,\n",
        "        'washout':'init',\n",
        "        'w_ridge_embedding':trial.suggest_float('w_ridge_embedding', 10.0, 20.0, log = True),\n",
        "        'mts_rep': trial.suggest_categorical('mts_rep', ['reservoir', 'output', 'id','last','mean','state']),\n",
        "        'bidir':'True', # trial.suggest_categorical('bidir', ['True', 'False']),\n",
        "        'circle': False,\n",
        "        'dimred_method':  trial.suggest_categorical('dimred_method', ['tenpca', None]),\n",
        "        'n_dim': trial.suggest_int('n_dim', 30, 75) if trial.suggest_categorical('dimred_method', ['tenpca', None]) == 'tenpca' else 30,\n",
        "        'use_input_bias':True,\n",
        "        'use_input_layer':'True', #trial.suggest_categorical('use_input_layer', ['True', 'False']),\n",
        "        'readout_type': None,\n",
        "        'threshold':0.3,\n",
        "        'svm_kernel': 'linear',\n",
        "        'svm_gamma': 0.005,\n",
        "        'svm_C': 5.0,\n",
        "        'w_ridge': 5.0,\n",
        "        'mlp_w_l2': 0.01,\n",
        "        'mlp_num_epochs': 2000,\n",
        "        'mlp_layout': (10, 10),\n",
        "        'mlp_batch_size': 32,\n",
        "        'mlp_learning_rate': 0.01,\n",
        "        'mlp_learning_rate_type': 'constant',\n",
        "        'plasticity_synaptic':None, # 'hebb'.'oja', 'covariance','bcm'\n",
        "        'theta_m':0.01,\n",
        "        'learning_rate':0.1,\n",
        "        'plasticity_intrinsic':None, # 'excitability', 'activation_function'\n",
        "        'new_activation_function':'tanh',\n",
        "        'excitability_factor':0.01,\n",
        "        'device': 'cpu'\n",
        "    }\n",
        "\n",
        "    config ['bidir']           = True if config ['bidir'] == 'True' else False\n",
        "    config ['use_input_layer'] = True if config ['use_input_layer'] == 'True' else False\n",
        "\n",
        "    if config['dimred_method'] is not None:\n",
        "        config['n_dim'] = min(config['n_dim'], config ['n_internal_units'])\n",
        "\n",
        "    # Lógica para ajustar washout si n_drop no es None\n",
        "    if config['n_drop'] is not None:\n",
        "        config['washout'] = trial.suggest_categorical ('washout', ['init', 'rand'])\n",
        "\n",
        "    rc_state, input_repr, Y = train_reservoir (config, X, Y, verbose = verbose)\n",
        "\n",
        "    dt_rc_state = rc_state.reshape (rc_state.shape[0], -1)\n",
        "\n",
        "    file_prefix_state = f\"results_state_{file_prefix}\"\n",
        "    file_prefix_input = f\"results_inter_{file_prefix}\"\n",
        "\n",
        "    accuracy_value_state_similarity, accuracy_value_state_X = evaluate_accuracy (trial, dt_rc_state, Y,\n",
        "                                                                                 state = True, file_prefix = file_prefix_state, verbose = verbose)\n",
        "    accuracy_value_input_similarity, accuracy_value_input_X = evaluate_accuracy (trial, input_repr, Y,\n",
        "                                                                                 state = False, file_prefix = file_prefix_input, verbose = verbose)\n",
        "\n",
        "    return max (accuracy_value_state_similarity, accuracy_value_input_similarity, accuracy_value_state_X, accuracy_value_input_X)\n",
        "\n",
        "\n",
        "\n",
        "def extract_parameters(filename):\n",
        "    pattern = r'dt_(Older|Younger)_([a-zA-Z]*)_(ICA_)?(features_)?(\\d+)_(\\d+).npy'\n",
        "    match = re.match(pattern, filename)\n",
        "\n",
        "    if match:\n",
        "        groups = match.groups()\n",
        "        selectChannels = groups[1] if groups[1] else 'default_value'  # Reemplaza 'default_value' con el valor por defecto que desees\n",
        "        freq           = groups[4]\n",
        "        decim          = groups[5]\n",
        "        ica            = True if groups[2] else  False\n",
        "        features       = True if groups[3] else False\n",
        "\n",
        "        return {\n",
        "            'selectChannels': selectChannels,\n",
        "            'freq': freq,\n",
        "            'decim': decim,\n",
        "            'ica': ica,\n",
        "            'features': features\n",
        "        }\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def create_objective (X, Y, file_prefix, verbose = True):\n",
        "    def objective (trial):\n",
        "        # función para entrenar y evaluar tu modelo\n",
        "        score = train_and_evaluate_model (trial, X, Y, file_prefix, verbose = verbose)\n",
        "        return score\n",
        "\n",
        "    # Definir el pruner: en este caso, usando el pruner MedianPruner\n",
        "    pruner = optuna.pruners.MedianPruner (n_startup_trials = 5, n_warmup_steps = 10)\n",
        "\n",
        "    return objective, pruner\n",
        "\n",
        "def check_and_load_files (channels = 's', ica = True, features = False,\n",
        "                          freq = 30, decim = 4, verbose = False):\n",
        "\n",
        "    # Check if the directory exists, if not, raise an exception\n",
        "    if not os.path.exists(\"./dataset\"):\n",
        "        raise FileNotFoundError(\"El directorio de datasets no se encuentra disponible.\")\n",
        "\n",
        "    # Name Files EEG data\n",
        "    file_RC_y = f\"./dataset/dt_Younger_{channels}{'_ICA_' if features else '_'}{'features_' if ica else ''}{freq}_{decim}.npy\"\n",
        "    file_RC_o = f\"./dataset/dt_Older_{channels}{'_ICA_' if features else '_'}{'features_' if ica else ''}{freq}_{decim}.npy\"\n",
        "\n",
        "    if verbose: print (f'file_RC_y: {file_RC_y}')\n",
        "    if verbose: print (f'file_RC_o: {file_RC_o}')\n",
        "\n",
        "    # Verificar si los archivos existen\n",
        "    if not os.path.exists(file_RC_y) or not os.path.exists(file_RC_o):\n",
        "        raise FileNotFoundError(\"Los ficheros de datasets no se encuentran disponibles.\")\n",
        "\n",
        "    # Cargar los datasets\n",
        "    dataset_RC_y = np.load (file_RC_y)\n",
        "    dataset_RC_o = np.load (file_RC_o)\n",
        "\n",
        "    if verbose: print(f'dataset_RC_y: {dataset_RC_y.shape}')\n",
        "    if verbose: print(f'dataset_RC_o: {dataset_RC_o.shape}')\n",
        "\n",
        "    # Concatenar los datasets\n",
        "    dt_classifier = np.concatenate ((dataset_RC_y, dataset_RC_o), axis = 0)\n",
        "\n",
        "    # Crear etiquetas para cada instancia\n",
        "    zeros_list = [0] * 23\n",
        "    ones_list  = [1] * 24\n",
        "\n",
        "    # Concatenar las dos listas\n",
        "    dt_labels = np.array (zeros_list + ones_list)\n",
        "\n",
        "    # Verificar las formas resultantes\n",
        "    if verbose: print (\"Forma de los datos concatenados:\", dt_classifier.shape)\n",
        "    if verbose: print (\"Forma de las etiquetas concatenadas:\", dt_labels.shape)\n",
        "\n",
        "    # Asignar datos y etiquetas\n",
        "    X = dt_classifier\n",
        "    Y = dt_labels\n",
        "\n",
        "    # Define the directory path para registrar los valores de lso hiperparametros y las metricas asociadas\n",
        "    directory = \"./optim_param_results\"\n",
        "        # Check if the directory exists, if not, create it\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "def main(args):\n",
        "    # Implementa la lógica principal del programa aquí\n",
        "    if args.verbose:\n",
        "        print(\"Running with the following parameters:\")\n",
        "        print(f\"Frequency: {args.freq}\")\n",
        "        print(f\"Decimation: {args.decim}\")\n",
        "        print(f\"Select Channels: {args.selectChannels}\")\n",
        "        print(f\"direct_files: {args.direct_files}\")\n",
        "        print(f\"ICA: {'Yes' if args.icaFlag else 'No'}\")\n",
        "        print(f\"Features: {'Yes' if args.featuresFlag else 'No'}\")\n",
        "        print(f\"Verbose: {args.verbose}\")\n",
        "    # Aquí iría el resto del procesamiento del programa\n",
        "    # Define variables based on arguments\n",
        "    freq           = args.freq\n",
        "    decim          = args.decim\n",
        "    ica            = args.icaFlag\n",
        "    features       = args.featuresFlag\n",
        "    verbose        = args.verbose\n",
        "    n_trials       = args.trials\n",
        "    directory_path = args.direct_files\n",
        "    selec_channels = args.selectChannels\n",
        "    # Load and display dimensions of the dataset files\n",
        "    files = os.listdir( directory_path )\n",
        "\n",
        "    zeros_list = [0] * 23\n",
        "    ones_list  = [1] * 24\n",
        "    # Concatenar las dos listas\n",
        "    dt_labels = np.array(zeros_list + ones_list)\n",
        "    freq  = 30\n",
        "    decim = 4\n",
        "    selectChannels_options = ['s','z', 'd', 'i','eeg']\n",
        "    ICAflag_options        = [True, False]\n",
        "    feature_options        = [True, False]\n",
        "\n",
        "    for selectChannels in selectChannels_options:\n",
        "        for ICAflag in ICAflag_options:\n",
        "            for featuresFlag in feature_options:\n",
        "                X, y_labels = check_and_load_files (channels = selectChannels, ica = ICAflag,\n",
        "                                       features = featuresFlag, freq = 30, decim = 4, verbose = verbose)\n",
        "\n",
        "                try:\n",
        "                    file_prefix = f\"dt_result_{'features_' if features else ''}{channels}_eeg_{'ica' if ica else 'noica'}_{freq}_{decim}\"\n",
        "\n",
        "                    if verbose: print (f'file_prefix: {file_prefix}')\n",
        "                    # Define objective function for Optuna\n",
        "                    objective, pruner = create_objective (X, y_labels, file_prefix, verbose = verbose)\n",
        "                    study             = optuna.create_study (direction = 'maximize', pruner = pruner)\n",
        "                    study.optimize (objective, n_trials = n_trials)\n",
        "\n",
        "                    best_trial = study.best_trial\n",
        "                    with open (f\"{file_prefix}_pt.txt\", \"a\") as f:\n",
        "                        f.write (\"\\n---\\n\")\n",
        "                        f.write (\"Mejor configuración:\\n\")\n",
        "                        f.write (f\"{best_trial.params}\\n\")\n",
        "                        f.write (f\"Mejor puntuación (f1_score): {best_trial.value}\\n\")\n",
        "                        for key, value in trial.params.items():\n",
        "                            f.write ( \"    {}: {}\".format( key, value ) )\n",
        "\n",
        "                    if verbose: print (\"Mejor configuración:\", best_trial.params)\n",
        "                    if verbose: print (\"Mejor puntuación:\", best_trial.value)\n",
        "                except Exception as e:\n",
        "                    print (e)\n",
        "if __name__ == \"__main__\":\n",
        "    if 'ipykernel' in sys.modules:\n",
        "        args = argparse.Namespace(\n",
        "            direct_files   ='./dataset',\n",
        "            freq           = 30,\n",
        "            decim          = 4,\n",
        "            selectChannels = 's',  # s, z, d, i, eeg\n",
        "            trials         = 1000,\n",
        "            icaFlag        = True,\n",
        "            featuresFlag   = True,\n",
        "            verbose        = True\n",
        "        )\n",
        "    else:\n",
        "        # Parse command-line arguments\n",
        "        parser = argparse.ArgumentParser(description='EEG Clustering Optimization')\n",
        "        parser.add_argument ('--direct_files',   type = str, default ='./dataset', help='Directory for EEG data files')\n",
        "        parser.add_argument ('--freq',           type = int, default = 30, help='Frequency for EEG data processing')\n",
        "        parser.add_argument ('--decim',          type = int, default = 4, help='Decimation factor for EEG data processing')\n",
        "        parser.add_argument ('--selectChannels', type = str, default = 's', help='Select channels for EEG data')\n",
        "        parser.add_argument ('--trials',         type = int, default = 1, help = \"El número de iteraciones (por defecto es 4).\")\n",
        "        parser.add_argument ('--icaFlag',      action = 'store_true', help = 'Flag to apply ICA on EEG data')\n",
        "        parser.add_argument ('--featuresFlag', action = 'store_true', help = 'Flag to use features for EEG data')\n",
        "        parser.add_argument ('--verbose',      action = 'store_true', help = 'Flag to enable verbose output')\n",
        "        args = parser.parse_args()\n",
        "\n",
        "    main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "-Zv_cGsfvEKU",
        "outputId": "2c582786-ae54-486e-d304-74cc5c3e90d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'optuna'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-12ba96e1e7c2>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}